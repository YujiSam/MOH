import logging
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from itertools import combinations
from collections import defaultdict, deque
import time
import random

class RecomendadorHabilidades:
    def __init__(self, grafo, cenarios_mercado, horizonte_anos=5, horas_por_ano=200):
        self.grafo = grafo
        self.cenarios_mercado = cenarios_mercado
        self.horizonte_anos = horizonte_anos
        self.horas_por_ano = horas_por_ano
        self.ordenacao_topologica = self._calcular_ordenacao_topologica()
        self.habilidades_basicas = self._identificar_habilidades_basicas()
        
    def _calcular_ordenacao_topologica(self):
        """Calcula ordena√ß√£o topol√≥gica do grafo"""
        graus_entrada = {no: 0 for no in self.grafo}
        arestas_saida = defaultdict(list)
        
        for no, dados in self.grafo.items():
            for prereq in dados['Pre_Reqs']:
                graus_entrada[no] += 1
                arestas_saida[prereq].append(no)
        
        fila = deque([no for no in self.grafo if graus_entrada[no] == 0])
        ordenacao = []
        
        while fila:
            no = fila.popleft()
            ordenacao.append(no)
            
            for vizinho in arestas_saida[no]:
                graus_entrada[vizinho] -= 1
                if graus_entrada[vizinho] == 0:
                    fila.append(vizinho)
        
        if len(ordenacao) != len(self.grafo):
            raise ValueError("Grafo cont√©m ciclos - n√£o √© poss√≠vel ordena√ß√£o topol√≥gica")
        
        return ordenacao
    
    def _identificar_habilidades_basicas(self):
        """Identifica habilidades sem pr√©-requisitos"""
        return [hab for hab in self.grafo if not self.grafo[hab]['Pre_Reqs']]
    
    def _calcular_valor_esperado(self, habilidade, ano_futuro=1):
        """
        Calcula valor esperado considerando cen√°rios de mercado e horizonte temporal
        """
        valor_base = self.grafo[habilidade]['Valor']
        demanda_base = self.grafo[habilidade].get('Demanda', 0.7)
        
        valor_esperado_total = 0
        
        for cenario_nome, cenario in self.cenarios_mercado.items():
            probabilidade = cenario['probabilidade']
            valor_cenario = valor_base
            
            # Aplicar b√¥nus/penalidade baseado no cen√°rio
            if habilidade in cenario['bonus_habilidades']:
                valor_cenario *= cenario['fator_bonus']
                logging.debug(f"  {habilidade} recebe b√¥nus no cen√°rio {cenario_nome}")
            elif habilidade in cenario['penalidade_habilidades']:
                valor_cenario *= 0.8  # Penalidade de 20%
                logging.debug(f"  {habilidade} recebe penalidade no cen√°rio {cenario_nome}")
            
            # Ajustar pela demanda e crescimento temporal
            fator_crescimento = 1 + (ano_futuro * 0.08)  # 8% de crescimento por ano
            fator_demanda = demanda_base * fator_crescimento
            
            valor_cenario_ajustado = valor_cenario * fator_demanda
            valor_esperado_total += valor_cenario_ajustado * probabilidade
        
        return valor_esperado_total
    
    def _obter_habilidades_disponiveis(self, habilidades_adquiridas):
        """Retorna habilidades que podem ser aprendidas (pr√©-requisitos satisfeitos)"""
        disponiveis = []
        for habilidade in self.grafo:
            if (habilidade not in habilidades_adquiridas and
                all(req in habilidades_adquiridas for req in self.grafo[habilidade]['Pre_Reqs'])):
                disponiveis.append(habilidade)
        return disponiveis
    
    def dp_horizonte_finito(self, habilidades_atuais, anos_look_ahead=3, max_habilidades=3):
        """
        Programa√ß√£o Din√¢mica em horizonte finito para recomendar pr√≥ximas habilidades
        """
        logging.info(f"Executando DP horizonte finito: {len(habilidades_atuais)} habilidades atuais, {anos_look_ahead} anos look-ahead")
        
        estado_inicial = {
            'habilidades': frozenset(habilidades_atuais),
            'tempo_disponivel': self.horas_por_ano * anos_look_ahead,
            'valor_acumulado': 0,
            'caminho': tuple(),
            'ano_atual': 0
        }
        
        # DP table: ano -> estado -> (valor_maximo, caminho)
        dp = {0: {estado_inicial['habilidades']: (0, tuple(), estado_inicial['tempo_disponivel'])}}
        melhor_global = (0, tuple(), estado_inicial['tempo_disponivel'])
        
        for ano in range(1, anos_look_ahead + 1):
            dp[ano] = {}
            logging.debug(f"Processando ano {ano}, estados no ano anterior: {len(dp[ano-1])}")
            
            for estado_hash in dp[ano-1]:
                valor_anterior, caminho_anterior, tempo_anterior = dp[ano-1][estado_hash]
                habilidades_atuais_set = set(estado_hash)
                
                # Op√ß√£o 1: N√£o aprender nada neste ano (manter estado)
                if estado_hash not in dp[ano] or valor_anterior > dp[ano][estado_hash][0]:
                    dp[ano][estado_hash] = (valor_anterior, caminho_anterior, tempo_anterior)
                
                # Op√ß√£o 2: Aprender habilidades dispon√≠veis
                habilidades_disponiveis = self._obter_habilidades_disponiveis(habilidades_atuais_set)
                
                for habilidade in habilidades_disponiveis:
                    dados_habilidade = self.grafo[habilidade]
                    tempo_necessario = dados_habilidade['Tempo']
                    
                    if tempo_anterior >= tempo_necessario:
                        # Calcular valor esperado considerando o ano futuro
                        valor_esperado = self._calcular_valor_esperado(habilidade, ano)
                        
                        # Novo estado
                        novas_habilidades = habilidades_atuais_set | {habilidade}
                        novo_tempo = tempo_anterior - tempo_necessario
                        novo_valor = valor_anterior + valor_esperado
                        novo_caminho = caminho_anterior + (habilidade,)
                        
                        estado_hash_novo = frozenset(novas_habilidades)
                        
                        # Atualizar DP se for melhor
                        if (estado_hash_novo not in dp[ano] or 
                            novo_valor > dp[ano][estado_hash_novo][0] or
                            (novo_valor == dp[ano][estado_hash_novo][0] and novo_tempo > dp[ano][estado_hash_novo][2])):
                            
                            dp[ano][estado_hash_novo] = (novo_valor, novo_caminho, novo_tempo)
                            
                            # Atualizar melhor global
                            if novo_valor > melhor_global[0]:
                                melhor_global = (novo_valor, novo_caminho, novo_tempo)
                
                # Limitar n√∫mero de estados para evitar explos√£o combinat√≥ria
                if len(dp[ano]) > 1000:
                    # Manter apenas os melhores estados
                    estados_ordenados = sorted(dp[ano].items(), key=lambda x: x[1][0], reverse=True)
                    dp[ano] = dict(estados_ordenados[:500])
        
        # Encontrar melhor solu√ß√£o
        melhor_valor, melhor_caminho, tempo_restante = melhor_global
        
        # Garantir que n√£o recomendamos mais que max_habilidades
        habilidades_recomendadas = list(melhor_caminho)[:max_habilidades]
        
        resultado = {
            'valor_esperado': melhor_valor,
            'proximas_habilidades': habilidades_recomendadas,
            'caminho_completo': list(melhor_caminho),
            'tempo_utilizado': (self.horas_por_ano * anos_look_ahead) - tempo_restante,
            'tempo_restante': tempo_restante,
            'horizonte_considerado': anos_look_ahead,
            'anos_otimizados': anos_look_ahead,
            'estados_explorados': sum(len(estados) for estados in dp.values())
        }
        
        logging.info(f"DP conclu√≠da: Valor esperado = {melhor_valor:.2f}, "
                    f"Habilidades recomendadas = {habilidades_recomendadas}")
        
        return resultado
    
    def busca_look_ahead(self, habilidades_atuais, profundidade=2, max_habilidades=3):
        """
        Busca com look ahead considerando transi√ß√µes de mercado
        """
        logging.info(f"Executando busca look-ahead: profundidade={profundidade}")
        
        melhor_sequencia = []
        melhor_valor = -1
        
        # Habilidades dispon√≠veis imediatamente
        habilidades_disponiveis = self._obter_habilidades_disponiveis(habilidades_atuais)
        
        # Gerar e avaliar sequ√™ncias
        for seq in self._gerar_sequencias_limitadas(habilidades_disponiveis, profundidade, max_habilidades):
            valor_sequencia = self._avaliar_sequencia_look_ahead(seq, habilidades_atuais, profundidade)
            
            if valor_sequencia > melhor_valor:
                melhor_valor = valor_sequencia
                melhor_sequencia = seq
        
        return {
            'proximas_habilidades': melhor_sequencia[:max_habilidades],
            'valor_esperado': melhor_valor,
            'profundidade_considerada': profundidade,
            'metodo': 'busca_look_ahead'
        }
    
    def _gerar_sequencias_limitadas(self, habilidades, profundidade, max_por_nivel=2):
        """Gera sequ√™ncias de habilidades limitadas para evitar explos√£o combinat√≥ria"""
        if profundidade == 0 or not habilidades:
            return [[]]
        
        sequencias = []
        
        # Considerar diferentes tamanhos de sequ√™ncia neste n√≠vel
        for tamanho_seq in range(1, min(len(habilidades), max_por_nivel) + 1):
            for comb in combinations(habilidades, tamanho_seq):
                seq_atual = list(comb)
                
                # Obter novas habilidades dispon√≠veis ap√≥s esta sequ√™ncia
                novas_habs_disponiveis = set(seq_atual)
                for hab in seq_atual:
                    novas_habs_disponiveis.update(self._obter_habilidades_disponiveis([hab]))
                
                # Remover habilidades j√° inclu√≠das
                novas_habs_disponiveis = [h for h in novas_habs_disponiveis if h not in seq_atual]
                
                # Recurs√£o para pr√≥xima profundidade
                for sub_seq in self._gerar_sequencias_limitadas(novas_habs_disponiveis, profundidade-1, max_por_nivel):
                    sequencias.append(seq_atual + sub_seq)
        
        return sequencias if sequencias else [[]]
    
    def _avaliar_sequencia_look_ahead(self, sequencia, habilidades_atuais, profundidade):
        """Avalia uma sequ√™ncia considerando cen√°rios futuros"""
        habilidades_temp = set(habilidades_atuais)
        valor_total = 0
        tempo_total = 0
        
        for i, habilidade in enumerate(sequencia):
            if tempo_total > self.horas_por_ano * profundidade:
                break
                
            if all(req in habilidades_temp for req in self.grafo[habilidade]['Pre_Reqs']):
                # Calcular valor considerando o ano futuro
                ano_futuro = min(i + 1, profundidade)
                valor_esperado = self._calcular_valor_esperado(habilidade, ano_futuro)
                valor_total += valor_esperado
                tempo_total += self.grafo[habilidade]['Tempo']
                habilidades_temp.add(habilidade)
        
        return valor_total
    
    def analisar_tendencias_mercado(self):
        """Analisa tend√™ncias de mercado para recomenda√ß√µes estrat√©gicas"""
        analise = {}
        
        for cenario_nome, cenario in self.cenarios_mercado.items():
            habilidades_prioritarias = []
            
            for habilidade in cenario['bonus_habilidades']:
                if habilidade in self.grafo:
                    valor_potencial = self._calcular_valor_esperado(habilidade, 2)  # 2 anos no futuro
                    habilidades_prioritarias.append({
                        'habilidade': habilidade,
                        'valor_potencial': valor_potencial,
                        'nome': self.grafo[habilidade]['Nome'],
                        'tempo': self.grafo[habilidade]['Tempo'],
                        'alinhamento': 'ALTO'
                    })
            
            # Ordenar por valor potencial
            habilidades_prioritarias.sort(key=lambda x: x['valor_potencial'], reverse=True)
            
            analise[cenario_nome] = {
                'probabilidade': cenario['probabilidade'],
                'descricao': cenario['descricao'],
                'habilidades_prioritarias': habilidades_prioritarias[:5],  # Top 5
                'impacto_esperado': sum(h['valor_potencial'] for h in habilidades_prioritarias[:3]) / 3
            }
        
        return analise
    
    def _calcular_alinhamento_tendencias(self, habilidade):
        """Calcula alinhamento da habilidade com tend√™ncias de mercado"""
        alinhamento = 0
        for cenario_nome, cenario in self.cenarios_mercado.items():
            if habilidade in cenario['bonus_habilidades']:
                alinhamento += cenario['probabilidade'] * 0.9  # Alto alinhamento
            elif habilidade not in cenario['penalidade_habilidades']:
                alinhamento += cenario['probabilidade'] * 0.4  # Alinhamento neutro
            else:
                alinhamento += cenario['probabilidade'] * 0.1  # Baixo alinhamento
        
        return alinhamento
    
    def _identificar_gaps_estrat√©gicos(self, perfil_atual):
        """Identifica gaps estrat√©gicos no perfil atual"""
        areas = {
            'Programa√ß√£o': ['S1', 'S3', 'S8'],
            'Dados/ML': ['S2', 'S4', 'S5', 'S6', 'H11'],
            'Cloud/DevOps': ['S7', 'S9'],
            'Seguran√ßa': ['H10'],
            'IoT/Emergentes': ['H12']
        }
        
        gaps = {}
        for area, habilidades_area in areas.items():
            habilidades_possuidas = [h for h in habilidades_area if h in perfil_atual]
            cobertura = len(habilidades_possuidas) / len(habilidades_area) if habilidades_area else 0
            
            if cobertura < 0.5:  # Menos de 50% de cobertura
                gaps[area] = {
                    'cobertura': cobertura,
                    'habilidades_faltantes': [h for h in habilidades_area if h not in perfil_atual],
                    'prioridade': 'ALTA' if cobertura < 0.2 else 'M√âDIA'
                }
        
        return gaps
    
    def _calcular_roi_esperado(self, habilidades):
        """Calcula ROI esperado para conjunto de habilidades"""
        if not habilidades:
            return 0
        
        tempo_total = sum(self.grafo[h]['Tempo'] for h in habilidades)
        valor_total = sum(self._calcular_valor_esperado(h, 1) for h in habilidades)
        
        return valor_total / tempo_total if tempo_total > 0 else 0
    
    def gerar_recomendacao_inteligente(self, perfil_atual, metodo='auto'):
        """
        Gera recomenda√ß√£o inteligente baseada no perfil e cen√°rios futuros
        """
        logging.info(f"Gerando recomenda√ß√£o para perfil: {perfil_atual}")
        
        # An√°lise do perfil atual
        gaps_estrategicos = self._identificar_gaps_estrat√©gicos(perfil_atual)
        tendencias_mercado = self.analisar_tendencias_mercado()
        
        # Escolher m√©todo baseado na complexidade
        if metodo == 'auto':
            if len(perfil_atual) <= 3:  # Perfil simples
                metodo = 'dp'
            else:  # Perfil complexo
                metodo = 'look_ahead'
        
        # Executar algoritmo de recomenda√ß√£o
        if metodo == 'dp':
            resultado = self.dp_horizonte_finito(perfil_atual, anos_look_ahead=3, max_habilidades=3)
        else:
            resultado = self.busca_look_ahead(perfil_atual, profundidade=2, max_habilidades=3)
        
        # Enriquecer resultado com an√°lise estrat√©gica
        habilidades_recomendadas = resultado['proximas_habilidades']
        
        analise_estrategica = {
            'alinhamento_medio': np.mean([self._calcular_alinhamento_tendencias(h) for h in habilidades_recomendadas]),
            'roi_esperado': self._calcular_roi_esperado(habilidades_recomendadas),
            'gaps_cobertos': [area for area, gap in gaps_estrategicos.items() 
                             if any(h in gap['habilidades_faltantes'] for h in habilidades_recomendadas)],
            'cenario_mais_favoravel': max(tendencias_mercado.items(), 
                                         key=lambda x: x[1]['impacto_esperado'])[0]
        }
        
        resultado.update({
            'analise_estrategica': analise_estrategica,
            'gaps_identificados': gaps_estrategicos,
            'tendencias_mercado': tendencias_mercado,
            'metodo_utilizado': metodo
        })
        
        return resultado
    
    def executar_analise_completa(self, perfis_teste=None):
        """
        Executa an√°lise completa para m√∫ltiplos perfis
        """
        if perfis_teste is None:
            perfis_teste = {
                'Iniciante': [],
                'Programador Junior': ['S1'],
                'Analista de Dados': ['S1', 'S2', 'S5'],
                'Desenvolvedor Backend': ['S1', 'S3', 'S8'],
                'Especialista Cloud': ['S1', 'S7', 'S8']
            }
        
        resultados = {}
        
        for perfil_nome, habilidades in perfis_teste.items():
            logging.info(f"Analisando perfil: {perfil_nome}")
            
            resultado = self.gerar_recomendacao_inteligente(habilidades)
            resultados[perfil_nome] = resultado
        
        return resultados
    
    def gerar_relatorio_detalhado(self, analise_completa):
        """
        Gera relat√≥rio detalhado do Desafio 5
        """
        print("=" * 80)
        print("DESAFIO 5 ‚Äî RECOMENDAR PR√ìXIMAS HABILIDADES - RELAT√ìRIO DETALHADO")
        print("=" * 80)
        print("üéØ OBJETIVO: Sugerir 2-3 pr√≥ximas habilidades maximizando valor esperado")
        print(f"üìÖ HORIZONTE: {self.horizonte_anos} anos | ‚è∞ HORAS/ANO: {self.horas_por_ano}h")
        print()
        
        # An√°lise de Cen√°rios de Mercado
        print("üìä CEN√ÅRIOS DE MERCADO (5 ANOS):")
        print("-" * 40)
        tendencias = analise_completa[list(analise_completa.keys())[0]]['tendencias_mercado']
        
        for cenario, dados in tendencias.items():
            print(f"\nüîÆ {cenario} ({dados['probabilidade']:.0%} probabilidade):")
            print(f"   {dados['descricao']}")
            print(f"   üéØ Habilidades Priorit√°rias:")
            for hab in dados['habilidades_prioritarias'][:3]:
                print(f"      ‚úì {hab['habilidade']}: {hab['nome']}")
                print(f"          Valor Potencial: {hab['valor_potencial']:.1f} | "
                      f"Tempo: {hab['tempo']}h")
        print()
        
        # Recomenda√ß√µes por Perfil
        print("üë• RECOMENDA√á√ïES POR PERFIL:")
        print("-" * 30)
        
        for perfil_nome, resultado in analise_completa.items():
            print(f"\nüéØ PERFIL: {perfil_nome}")
            print(f"   Habilidades Atuais: {', '.join(resultado.get('habilidades_atuais', [])) or 'Nenhuma'}")
            
            if resultado['proximas_habilidades']:
                print(f"   üèÜ PR√ìXIMAS HABILIDADES RECOMENDADAS:")
                for i, habilidade in enumerate(resultado['proximas_habilidades'], 1):
                    dados = self.grafo[habilidade]
                    valor_esperado = self._calcular_valor_esperado(habilidade, 1)
                    alinhamento = self._calcular_alinhamento_tendencias(habilidade)
                    
                    print(f"      {i}. {habilidade} - {dados['Nome']}")
                    print(f"          ‚è±Ô∏è  {dados['Tempo']}h | üí∞ Valor: {dados['Valor']} | "
                          f"üéØ Valor Esperado: {valor_esperado:.1f}")
                    print(f"          üìä Alinhamento: {alinhamento:.0%} | "
                          f"üìö Pr√©-reqs: {', '.join(dados['Pre_Reqs']) or 'Nenhum'}")
                
                # M√©tricas da recomenda√ß√£o
                analise = resultado['analise_estrategica']
                print(f"   üìà M√âTRICAS DA RECOMENDA√á√ÉO:")
                print(f"      Valor Esperado Total: {resultado['valor_esperado']:.1f}")
                print(f"      Alinhamento M√©dio: {analise['alinhamento_medio']:.0%}")
                print(f"      ROI Esperado: {analise['roi_esperado']:.3f} pontos/hora")
                print(f"      Cen√°rio Mais Favor√°vel: {analise['cenario_mais_favoravel']}")
                
                if analise['gaps_cobertos']:
                    print(f"      üéØ Gaps Cobertos: {', '.join(analise['gaps_cobertos'])}")
                
                print(f"   üîß M√âTODO: {resultado['metodo_utilizado'].upper()} | "
                      f"Horizonte: {resultado.get('horizonte_considerado', resultado.get('profundidade_considerada', 'N/A'))} anos")
            else:
                print("   ‚ùå Nenhuma recomenda√ß√£o poss√≠vel com o perfil atual")
        
        # An√°lise Comparativa
        print("\nüìä AN√ÅLISE COMPARATIVA ENTRE PERFIS:")
        print("-" * 45)
        
        comparacao = []
        for perfil_nome, resultado in analise_completa.items():
            if resultado['proximas_habilidades']:
                comparacao.append({
                    'Perfil': perfil_nome,
                    'Habilidades_Recomendadas': ', '.join(resultado['proximas_habilidades']),
                    'Valor_Esperado': resultado['valor_esperado'],
                    'ROI': resultado['analise_estrategica']['roi_esperado'],
                    'Alinhamento': resultado['analise_estrategica']['alinhamento_medio']
                })
        
        if comparacao:
            df_comparacao = pd.DataFrame(comparacao)
            print(df_comparacao.to_string(index=False))
        
        # Insights Estrat√©gicos
        print("\nüí° INSIGHTS ESTRAT√âGICOS:")
        print("-" * 30)
        
        # Habilidade mais recomendada
        todas_recomendacoes = []
        for resultado in analise_completa.values():
            todas_recomendacoes.extend(resultado['proximas_habilidades'])
        
        if todas_recomendacoes:
            hab_mais_recomendada = max(set(todas_recomendacoes), key=todas_recomendacoes.count)
            freq = todas_recomendacoes.count(hab_mais_recomendada)
            print(f"   üéØ Habilidade Mais Recomendada: {hab_mais_recomendada} "
                  f"({freq} de {len(analise_completa)} perfis)")
        
        # Tend√™ncias identificadas
        print("   üìà Tend√™ncias Identificadas:")
        cenario_dominante = max(tendencias.items(), key=lambda x: x[1]['probabilidade'])
        print(f"      ‚Ä¢ Cen√°rio mais prov√°vel: {cenario_dominante[0]} ({cenario_dominante[1]['probabilidade']:.0%})")
        
        # Recomenda√ß√µes gerais
        print("   üöÄ Recomenda√ß√µes Gerais:")
        print("      ‚Ä¢ Focar em habilidades com alto alinhamento a m√∫ltiplos cen√°rios")
        print("      ‚Ä¢ Considerar ROI (Valor/Tempo) al√©m do valor absoluto")
        print("      ‚Ä¢ Desenvolver habilidades b√°sicas antes de especializa√ß√µes")
        print("      ‚Ä¢ Manter diversifica√ß√£o para mitigar riscos de mercado")
        
        return {
            'analise_completa': analise_completa,
            'tendencias_mercado': tendencias,
            'comparacao_perfis': comparacao
        }
    
    def gerar_visualizacao_completa(self, analise_completa):
        """Gera visualiza√ß√£o completa para o Desafio 5"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('Desafio 5 ‚Äî Sistema de Recomenda√ß√£o de Habilidades\n(DP Horizonte Finito + An√°lise de Mercado)', 
                    fontsize=16, weight='bold')
        
        # Gr√°fico 1: Recomenda√ß√µes por Perfil
        perfis = list(analise_completa.keys())
        valores_esperados = [analise_completa[p]['valor_esperado'] for p in perfis]
        num_recomendacoes = [len(analise_completa[p]['proximas_habilidades']) for p in perfis]
        
        x = np.arange(len(perfis))
        largura = 0.35
        
        bars1 = ax1.bar(x - largura/2, valores_esperados, largura, label='Valor Esperado', 
                       color='lightgreen', edgecolor='darkgreen')
        bars2 = ax1.bar(x + largura/2, num_recomendacoes, largura, label='N¬∫ Habilidades Recomendadas', 
                       color='lightblue', edgecolor='darkblue')
        
        ax1.set_title('Recomenda√ß√µes por Perfil - Valor Esperado vs Quantidade')
        ax1.set_xlabel('Perfil')
        ax1.set_ylabel('Valor Esperado / Quantidade')
        ax1.set_xticks(x)
        ax1.set_xticklabels(perfis, rotation=15)
        ax1.legend()
        ax1.grid(axis='y', alpha=0.3)
        
        # Adicionar valores
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                        f'{height:.1f}' if bars == bars1 else f'{height:.0f}', 
                        ha='center', va='bottom', fontsize=9)
        
        # Gr√°fico 2: An√°lise de Cen√°rios de Mercado
        tendencias = analise_completa[perfis[0]]['tendencias_mercado']
        cenarios = list(tendencias.keys())
        probabilidades = [tendencias[c]['probabilidade'] for c in cenarios]
        impactos = [tendencias[c]['impacto_esperado'] for c in cenarios]
        
        x = np.arange(len(cenarios))
        largura = 0.35
        
        bars1 = ax2.bar(x - largura/2, probabilidades, largura, label='Probabilidade', 
                       color='gold', edgecolor='darkorange')
        bars2 = ax2.bar(x + largura/2, impactos, largura, label='Impacto Esperado', 
                       color='lightcoral', edgecolor='darkred')
        
        ax2.set_title('Cen√°rios de Mercado - Probabilidade vs Impacto')
        ax2.set_xlabel('Cen√°rio')
        ax2.set_ylabel('Probabilidade / Impacto')
        ax2.set_xticks(x)
        ax2.set_xticklabels(cenarios, rotation=15)
        ax2.legend()
        ax2.grid(axis='y', alpha=0.3)
        
        # Gr√°fico 3: ROI e Alinhamento das Recomenda√ß√µes
        rois = []
        alinhamentos = []
        perfis_validos = []
        
        for perfil in perfis:
            resultado = analise_completa[perfil]
            if resultado['proximas_habilidades']:
                rois.append(resultado['analise_estrategica']['roi_esperado'])
                alinhamentos.append(resultado['analise_estrategica']['alinhamento_medio'])
                perfis_validos.append(perfil)
        
        if perfis_validos:
            x = np.arange(len(perfis_validos))
            largura = 0.35
            
            bars1 = ax3.bar(x - largura/2, rois, largura, label='ROI Esperado (Pontos/Hora)', 
                           color='lightseagreen', edgecolor='darkcyan')
            bars2 = ax3.bar(x + largura/2, alinhamentos, largura, label='Alinhamento com Tend√™ncias', 
                           color='mediumpurple', edgecolor='darkviolet', alpha=0.7)
            
            ax3.set_title('ROI e Alinhamento das Recomenda√ß√µes')
            ax3.set_xlabel('Perfil')
            ax3.set_ylabel('ROI / Alinhamento')
            ax3.set_xticks(x)
            ax3.set_xticklabels(perfis_validos, rotation=15)
            ax3.legend()
            ax3.grid(axis='y', alpha=0.3)
            
            # Adicionar valores
            for i, (roi, alinh) in enumerate(zip(rois, alinhamentos)):
                ax3.text(i - largura/2, roi + 0.01, f'{roi:.3f}', ha='center', va='bottom', fontsize=8)
                ax3.text(i + largura/2, alinh + 0.01, f'{alinh:.0%}', ha='center', va='bottom', fontsize=8)
        
        # Gr√°fico 4: Frequ√™ncia das Habilidades Recomendadas
        todas_recomendacoes = []
        for resultado in analise_completa.values():
            todas_recomendacoes.extend(resultado['proximas_habilidades'])
        
        if todas_recomendacoes:
            freq_series = pd.Series(todas_recomendacoes).value_counts()
            
            habilidades = freq_series.index.tolist()
            frequencias = freq_series.values.tolist()
            
            bars = ax4.bar(habilidades, frequencias, color='lightcoral', edgecolor='darkred', alpha=0.7)
            
            ax4.set_title('Frequ√™ncia das Habilidades nas Recomenda√ß√µes')
            ax4.set_xlabel('Habilidade')
            ax4.set_ylabel('Frequ√™ncia de Recomenda√ß√£o')
            ax4.grid(axis='y', alpha=0.3)
            
            # Adicionar valores
            for bar, freq in zip(bars, frequencias):
                ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.1,
                        f'{freq}', ha='center', va='bottom', fontweight='bold')
        else:
            ax4.text(0.5, 0.5, 'NENHUMA RECOMENDA√á√ÉO\nGERADA', 
                    ha='center', va='center', transform=ax4.transAxes, 
                    fontsize=16, weight='bold', color='red')
            ax4.set_title('Frequ√™ncia das Habilidades nas Recomenda√ß√µes')
        
        plt.tight_layout()
        return fig

def executar_desafio5(grafo, cenarios_mercado):
    """
    Fun√ß√£o principal do Desafio 5
    """
    logging.info("=" * 60)
    logging.info("INICIANDO DESAFIO 5 - RECOMENDAR PR√ìXIMAS HABILIDADES")
    logging.info("=" * 60)
    
    try:
        # Criar recomendador
        recomendador = RecomendadorHabilidades(grafo, cenarios_mercado)
        
        # Executar an√°lise completa
        print("üîç Executando an√°lise completa de recomenda√ß√µes...")
        analise_completa = recomendador.executar_analise_completa()
        
        # Gerar relat√≥rio
        relatorio = recomendador.gerar_relatorio_detalhado(analise_completa)
        
        # Gerar visualiza√ß√£o
        print("üìä Gerando visualiza√ß√µes...")
        fig = recomendador.gerar_visualizacao_completa(analise_completa)
        
        logging.info("Desafio 5 executado com sucesso")
        
        return {
            'sucesso': True,
            'analise_completa': analise_completa,
            'relatorio': relatorio,
            'figura': fig
        }
        
    except Exception as e:
        logging.error(f"Erro no Desafio 5: {e}")
        return {
            'sucesso': False,
            'erro': str(e)
        }

if __name__ == "__main__":
    # Configurar logging para teste
    logging.basicConfig(level=logging.INFO)
    
    # Dados de teste
    from dados import HABILIDADES, CENARIOS_MERCADO
    
    # Executar desafio
    resultado = executar_desafio5(HABILIDADES, CENARIOS_MERCADO)
    
    if resultado['sucesso']:
        print("\nüéâ Desafio 5 conclu√≠do com sucesso!")
        plt.show()  # Mostrar gr√°ficos
    else:
        print(f"‚ùå Erro: {resultado['erro']}")